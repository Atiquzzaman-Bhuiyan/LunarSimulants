# -*- coding: utf-8 -*-
"""XMLParser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_YoIC8tdAQl66V1oKM3rnQ7VH4rL40HD

This notebook is used to implement a XML parser for image annotation.
"""

import os
import cv2
import numpy as np
import xml.etree.ElementTree as ET
from google.colab.patches import cv2_imshow

"""## XML Parser Implementation"""

class XMLParser:
    """A XML parser for loading annotated CT image.
    """
    def __init__(self, xml_path: str, labels: list[str], thickness=1):
        """Initialize a XML parser.

        Args:
            xml_path: path to .xml file.
            labels: labels for parsing.
            thickness: polyline thickness in drawing.
        """

        ## create annotation label map (label->idx)
        self.labels = {label: idx for idx, label in enumerate(sorted(labels))}

        ## parse the .xml file to a tree
        tree = ET.parse(xml_path)
        root = tree.getroot()

        ## select the images from root
        self.images = [child for child in root if child.tag == "image"]
        self.images = sorted(self.images, key=lambda x: int(x.attrib['id']))

        ## polyline thickness
        self.thickness = thickness

    def __len__(self)->int:
        """Size of the annotated images.
        """
        return len(self.images)

    def __getitem__(self, idx: int)->dict:
        """Annotation of the idx image.
        """
        return self._parse_image_annotation(self.images[idx])

    def _parse_image_annotation(self, root: ET.Element)->dict:
        """Parse the polygons/polylines information based on its annotation.

        Args:
            root: an image root in the tree.

        Return:
            annotation: annotation dictionary of the image.
        """
        annotation = root.attrib.copy()

        ## parse the annotation and save to the dict
        annotation['records'] = []

        ## initialize segmentation mask
        H = int(annotation["height"])
        W = int(annotation["width"])
        canvas = np.zeros((H, W, len(self.labels)), dtype=np.uint8)

        for child in root:
            label = child.attrib['label']

            if label not in self.labels:
                continue

            record = {}

            if child.tag == "polygon" or child.tag == "polyline":
                record["type"]   = child.tag
                record["label"]  = self.labels[label]
                record["points"] = child.attrib["points"]

                annotation['records'].append(record)

                points = self._parse_points(child.attrib['points'])

                ## draw polygon/polyline on individual channel
                label_idx = self.labels[label]
                if child.tag == "polygon":
                    _canvas = canvas[:,:,label_idx].copy()
                    canvas[:,:,label_idx] = self._draw_polygon(_canvas, points)
                else:
                    _canvas = canvas[:,:,label_idx].copy()
                    canvas[:,:,label_idx] = self._draw_polyline(_canvas, points)

        annotation["mask"] = canvas

        return annotation

    def _draw_polygon(self, canvas, points):
        """
        A helper function to draw the polygon on canvas.
        """

        canvas = cv2.fillPoly(canvas, [points], 1)

        return canvas

    def _draw_polyline(self, canvas, points):
        """
        A helper function to draw the polyline on canvas.
        """

        canvas = cv2.polylines(canvas, [points], False, 1, thickness=self.thickness)

        return canvas

    def _parse_points(self, points):
        """
        A helper function to parse points from .xml file.
        """

        points = points.split(";")

        pts = []

        for point in points:
            x, y = point.split(",")
            x, y = eval(x), eval(y)

            pts.append((x, y))

        pts = np.array(pts).reshape((-1, 1, 2)).astype(int)

        return pts

# CT_LABEL = ["crack", "pore"]
# XML_PATH = "/content/SA_annotations.xml"    ## change xml_path as needed

# parser = XMLParser(XML_PATH, CT_LABEL)
# print(f"{XML_PATH} has {len(parser)} annotated images.")

"""Once you finish, you could index the parser to receive necessary information as follows (`annotation["mask"]` includes annotation of 'crack' and 'pore' on individual channel)."""

# idx = 10
# annotation = parser[idx]
# segmentation_mask = annotation["mask"]

"""Crack segmentation:"""

# channel = parser.labels["crack"]
# cv2_imshow(segmentation_mask[:,:,channel] * 255)

"""Pore segmentation:"""

# channel = parser.labels["pore"]
# cv2_imshow(segmentation_mask[:,:,channel] * 255)

"""# PyTorch Dataset Implementation"""

import torch
from torch.utils.data import Dataset
from torchvision.io import read_image
import torchvision.transforms as transforms

class CTImageDataset(Dataset):
    """CT image dataset. This implementation combines a list of .xml annotations as the dataset.

    Args:
        img_root: CT image path root.
        xml_paths: list of .xml parser path.
        thickness: polyline thickness in drawing.
        transform: image transform
    """
    def __init__(self, img_root, xml_paths, labels=[], thickness=2, transform=None):
        self.img_root= img_root
        self.parsers = [XMLParser(path, labels, thickness) for path in xml_paths]

        prefix_sum  = [0]

        for parser in self.parsers:
            prefix_sum.append(prefix_sum[-1] + len(parser))

        self.prefix_sum = prefix_sum

        ## image transform
        self.transform  = transform

    def __len__(self):
        return self.prefix_sum[-1]

    def __getitem__(self, idx):

        if idx >= len(self):
            raise IndexError

        ## handle negative idx
        while idx < 0:
            idx += len(self)

        ## determine which parser to use
        parser_idx = self._idxSearch(idx)
        parser = self.parsers[parser_idx]

        ## determine idx for that parser
        annotation_idx = idx - self.prefix_sum[parser_idx]
        # print(f"parser_idx: {parser_idx}, annotation_idx: {annotation_idx}")

        ## retrieve image and segmentation mask
        annotation = parser[annotation_idx]

        image_path = os.path.join(self.img_root, annotation["name"])

        image    = cv2.imread(image_path, 0)
        image    = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  ## convert 1-channel gray image to 3-channel RGB image
        seg_mask = annotation['mask']

        ## transform to tensor
        image    = self._toTensor(image)
        seg_mask = self._toTensor(seg_mask)

        if self.transform:
            merged = torch.cat([image, seg_mask], dim=0)
            merged = self.transform(merged)

            image    = merged[:3, :, :]
            seg_mask = merged[3:, :, :]

        return image, seg_mask

    def _idxSearch(self, target):
        """Find index of target.
        """

        N = len(self.parsers)

        for i in range(N):
            if self.prefix_sum[i] <= target < self.prefix_sum[i+1]:
                return i

        return N-1

    def _toTensor(self, img):
        """A helper function to transform cv2 img to tensor.

        Args:
            img[H, W, C]: image loaded from OpenCV

        Return:
            tensor[C, H, W]: tensor of the image
        """

        if len(img.shape) == 2:
            img = img[:, :, np.newaxis]

        tensor = torch.from_numpy(img)

        ## from [H, W, C] to [C, H, W] shape
        tensor = tensor.permute([2, 0, 1])
        tensor = tensor.float()

        return tensor

    @property
    def labels(self):
        return self.parsers[0].labels

"""Image and annotation path:"""

IMG_ROOT = "/content/drive/MyDrive/Micro and Nano-CT/Data/OPC_CT_Labelling"
XML_ROOT = "/content/drive/MyDrive/Micro and Nano-CT/Data/OPC_CT_Labelling/annotations"

"""Create PyTorch dataset:"""

xml_paths = os.listdir(XML_ROOT)
xml_paths = [os.path.join(XML_ROOT, path) for path in xml_paths if ".xml" in path]

transform_list = [transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(), transforms.RandomCrop([1024, 1024])]
transform = transforms.Compose(transform_list)

dataset = CTImageDataset(IMG_ROOT, xml_paths, labels=["crack", "pore"], transform=transform)
print(f"CTImageDataset has {len(dataset)} images in total.")
print(dataset.labels)

idx = 400

X, y = dataset[idx]

"""Plot the CT image:"""

cv2_imshow(X.numpy().transpose(1, 2, 0))

"""Plot the crack:"""

cv2_imshow(y[0, :, :].numpy() * 255)

"""Plot the pore:"""

cv2_imshow(y[1, :, :].numpy() * 255)

"""## DataLoader"""

from torch.utils.data import random_split, DataLoader

train_dataset = CTImageDataset(IMG_ROOT, xml_paths, labels=["crack", "pore"], thickness=2, transform=transform)
val_dataset   = CTImageDataset(IMG_ROOT, xml_paths, labels=["crack", "pore"], thickness=2, transform=None)

## split dataset
train_ratio = 0.8
train_size = int(train_ratio * len(train_dataset))
val_size = len(train_dataset) - train_size

train_dataset, _ = random_split(train_dataset, [train_size, val_size])
_, val_dataset = random_split(val_dataset, [train_size, val_size])

## wrap to dataloader
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)

for X, y in train_loader:
    print(X.shape, y.shape)